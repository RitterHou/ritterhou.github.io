<!DOCTYPE html><html lang="zh-Hans"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><title>HDFS的安装和使用 - 侯锐的思考与分享</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0"><meta name="keywords" content="大数据,分布式系统"><meta name="description" content="&lt;p&gt;正如在&lt;a href=&#34;/2021/04/11/Hadoop-Study-Notes/&#34;&gt;Hadoop学习笔记&lt;/a&gt;中所介绍的那样，我们已经安装好了Java环境并且设置好了&lt;code&gt;JAVA_HOME&lt;/code&gt;环境变量，并且下载解压了Hadoop的压缩包。&lt;/p&gt;
&lt;p&gt;我们准备三台机器，并且预计将它们的职责设置如下&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;机器&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;角色&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;172.19.65.196&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NameNode&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;172.19.72.108&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;DataNode&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;172.19.72.112&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;DataNode&lt;/td&gt;
&lt;/tr&gt;
&lt;/"><link rel="stylesheet" href="/css/style.css"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="侯锐的思考与分享" type="application/atom+xml"></head><body><div class="container"><header class="header"><div class="blog-title"><a href="/" class="logo">侯锐的思考与分享</a><div class="subtitle"></div></div><nav class="navbar"><ul class="menu"><li class="menu-item"><a href="/" class="menu-item-link" data-no-instant>主页</a></li><li class="menu-item"><a href="/atom.xml" class="menu-item-link" data-no-instant>订阅</a></li><li class="menu-item"><a href="/search" class="menu-item-link" data-no-instant>搜索</a></li></ul></nav></header><article class="post"><div class="post-title"><h1 class="article-title">HDFS的安装和使用</h1></div><div class="post-meta"><span class="post-time">2021-04-12</span></div><div class="post-content"><p>正如在<a href="/2021/04/11/Hadoop-Study-Notes/">Hadoop学习笔记</a>中所介绍的那样，我们已经安装好了Java环境并且设置好了<code>JAVA_HOME</code>环境变量，并且下载解压了Hadoop的压缩包。</p><p>我们准备三台机器，并且预计将它们的职责设置如下</p><table><thead><tr><th align="left">机器</th><th align="left">角色</th></tr></thead><tbody><tr><td align="left">172.19.65.196</td><td align="left">NameNode</td></tr><tr><td align="left">172.19.72.108</td><td align="left">DataNode</td></tr><tr><td align="left">172.19.72.112</td><td align="left">DataNode</td></tr></tbody></table><h2 id="实现ssh免密访问"><a href="#实现ssh免密访问" class="headerlink" title="实现ssh免密访问"></a>实现ssh免密访问</h2><p>在三台机器上面创建<code>hadoop</code>用户并且进入用户的根目录，在三台机器上执行命令创建ssh公私钥</p><pre><code>ssh-keygen -t rsa
</code></pre><p>之后在NameNode上面执行</p><pre><code>cat ~/.ssh/id_rsa.pub
</code></pre><p>获取到master节点的公钥，之后在三台机器（包括master节点自己）上面执行</p><pre><code>vi ~/.ssh/authorized_keys
</code></pre><p>把获取到的master节点的公钥复制进去并保存，随后执行</p><pre><code>chmod 644 ~/.ssh/authorized_keys
</code></pre><p>改变文件的权限信息，之后在NameNode上面执行ssh命令应该就能够实现免密访问了</p><pre><code>ssh hadoop@172.19.65.196
ssh hadoop@172.19.72.108
ssh hadoop@172.19.72.112
</code></pre><p>随后我们可以使用<code>rsync</code>命令将hadoop压缩包传输到另外两个节点上面去，传输完毕解压即可</p><pre><code>rsync -azvhP ./hadoop-3.3.2.tar.gz hadoop@172.19.72.108:/home/hadoop
rsync -azvhP ./hadoop-3.3.2.tar.gz hadoop@172.19.72.112:/home/hadoop
</code></pre><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>在NameNode上面创建两个文件夹</p><pre><code>cd ~
mkdir namenode
mkdir name
</code></pre><p>在所有DataNode上面创建文件夹</p><pre><code>cd ~
mkdir data
</code></pre><h3 id="1-修改所有机器的hadoop-env-sh文件"><a href="#1-修改所有机器的hadoop-env-sh文件" class="headerlink" title="1. 修改所有机器的hadoop-env.sh文件"></a>1. 修改所有机器的<code>hadoop-env.sh</code>文件</h3><pre><code>vi ~/hadoop-3.3.2/etc/hadoop/hadoop-env.sh
</code></pre><p>添加配置如下</p><pre><code>JAVA_HOME=$JAVA_HOME
</code></pre><h3 id="2-修改所有机器的core-site-xml文件"><a href="#2-修改所有机器的core-site-xml文件" class="headerlink" title="2. 修改所有机器的core-site.xml文件"></a>2. 修改所有机器的<code>core-site.xml</code>文件</h3><pre><code>vi ~/hadoop-3.3.2/etc/hadoop/core-site.xml
</code></pre><p>添加配置如下</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--HDFS的URI--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://172.19.65.196:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--存储namenode的信息--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="3-修改所有机器的hdfs-site-xml文件"><a href="#3-修改所有机器的hdfs-site-xml文件" class="headerlink" title="3. 修改所有机器的hdfs-site.xml文件"></a>3. 修改所有机器的<code>hdfs-site.xml</code>文件</h3><pre><code>vi ~/hadoop-3.3.2/etc/hadoop/hdfs-site.xml
</code></pre><p>添加配置如下</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--存储hdfs命名空间的元数据--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--存储物理文件块--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--副本个数--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--不强制使用hostname，因为我用的是IP地址，默认开启--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.datanode.registration.ip-hostname-check<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="4-修改所有机器的workers文件"><a href="#4-修改所有机器的workers文件" class="headerlink" title="4. 修改所有机器的workers文件"></a>4. 修改所有机器的<code>workers</code>文件</h3><pre><code>vi ~/hadoop-3.3.2/etc/hadoop/workers
</code></pre><p>修改配置如下</p><pre><code>172.19.72.108
172.19.72.112
</code></pre><h2 id="启动HDFS"><a href="#启动HDFS" class="headerlink" title="启动HDFS"></a>启动HDFS</h2><p>在NameNode上执行命令格式化hdfs</p><pre><code>./hadoop-3.3.2/bin/hdfs namenode -format
</code></pre><p>随后在NameNode上启动hdfs</p><pre><code>./hadoop-3.3.2/sbin/start-dfs.sh
</code></pre><p>在NameNode上执行jps能看到有NameNode和SecondaryNameNode进程</p><pre><code>[hadoop@lin-65-196 ~]$ jps
30690 SecondaryNameNode
30819 Jps
30462 NameNode
</code></pre><p>在DataNode上就有DataNode进程</p><pre><code>[hadoop@lin-72-108 ~]$ jps
19984 Jps
19909 DataNode
</code></pre><p>在NameNode上往hdfs写入数据</p><pre><code>./hadoop-3.3.2/bin/hadoop fs -mkdir -p /test/input
./hadoop-3.3.2/bin/hadoop fs -put ~/hadoop-3.3.2/etc/hadoop/core-site.xml /test/input
</code></pre><p>访问<a target="_blank" rel="noopener" href="http://172.19.65.196:9870/explorer.html#/test/input">http://172.19.65.196:9870/explorer.html#/test/input</a>就可以看到我们创建的文件了</p><p><img src="/images/20210412/1.png"></p><p>测试完毕可以停止hdfs</p><pre><code>./hadoop-3.3.2/sbin/stop-dfs.sh
</code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1435549">快速搭建 HDFS 系统（超详细版）</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/qingyunzong/p/8496127.html">Hadoop学习之路（四）Hadoop集群搭建和简单应用</a></p></div><div class="post-copyright"><div><strong>本文链接：</strong> <span title="HDFS的安装和使用">https://www.nosuchfield.com/2021/04/12/Installation-and-use-of-HDFS/</span></div><div><strong>版权声明： </strong>本博客所有文章均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处！</div></div><style>summary{cursor:pointer;margin-bottom:10px}summary:focus{outline:0}</style><script src="/js/code-enhancer.js"></script><script src="/js/pangu.min.js"></script><script>pangu.spacingPage()</script><script>function backToTop(){document.body.scrollTop=0,document.documentElement.scrollTop=0}</script><script defer src="https://cloud.umami.is/script.js" data-website-id="267e4aaf-8cb5-464d-b16c-89e66283e505"></script><div class="post-footer"><ul class="post-tag-list" itemprop="keywords"><li class="post-tag-list-item"><a class="post-tag-list-link" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/" rel="tag">分布式系统</a></li><li class="post-tag-list-item"><a class="post-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li></ul><span onclick="backToTop()" class="top">返回顶部</span></div></article><footer><span>&copy; 2015 - 2025</span> <span class="author">Raymond</span> <span style="float:right"><span class="upyun">本网站由<a target="_blank" rel="noopener" href="https://www.upyun.com/?utm_source=lianmeng&utm_medium=referral"> <img src="/images/others/upyun.png"></a>提供CDN加速&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span> <a class="filing" href="https://beian.miit.gov.cn/" target="_blank">苏ICP备15057335号</a> <a class="github" href="https://github.com/RitterHou" target="_blank">GitHub</a></span></footer></div></body></html>